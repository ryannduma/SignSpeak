{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SignSpeak: Sign Language Recognition Model Training\n",
        "\n",
        "This notebook covers the training pipeline for the sign language recognition model used in the SignSpeak application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Add src directory to path\n",
        "sys.path.append(os.path.abspath('../src'))\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation\n",
        "\n",
        "In this section, we'll load and prepare the data for training. This assumes we've already extracted features using the data_exploration.ipynb notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define a custom PyTorch Dataset for sign language data\n",
        "class SignLanguageDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            features: Processed keypoint features\n",
        "            labels: Sign labels\n",
        "        \"\"\"\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Convert to PyTorch tensors\n",
        "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return feature, label\n",
        "\n",
        "# Function to load sample data (in a real implementation, this would load from files)\n",
        "def load_sample_data(num_samples=100, num_frames=30, num_features=189, num_classes=5):\n",
        "    \"\"\"\n",
        "    Generate sample data for demonstration purposes.\n",
        "    \n",
        "    Args:\n",
        "        num_samples: Number of sign samples\n",
        "        num_frames: Number of frames per sign\n",
        "        num_features: Number of features per frame\n",
        "        num_classes: Number of sign classes\n",
        "        \n",
        "    Returns:\n",
        "        X: Features (num_samples, num_frames, num_features)\n",
        "        y: Labels (num_samples,)\n",
        "    \"\"\"\n",
        "    # Generate random features\n",
        "    X = np.random.randn(num_samples, num_frames, num_features).astype(np.float32)\n",
        "    \n",
        "    # Generate random labels\n",
        "    y = np.random.randint(0, num_classes, size=num_samples).astype(np.int64)\n",
        "    \n",
        "    print(f\"Generated {num_samples} samples with shape {X.shape}\")\n",
        "    return X, y\n",
        "\n",
        "# Load sample data\n",
        "X, y = load_sample_data()\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "We'll define a recurrent neural network (RNN) model for sign language recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class SignRecognitionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.2):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_size: Feature size (number of keypoint features)\n",
        "            hidden_size: Size of LSTM hidden layers\n",
        "            num_layers: Number of LSTM layers\n",
        "            num_classes: Number of sign classes\n",
        "            dropout_rate: Dropout probability\n",
        "        \"\"\"\n",
        "        super(SignRecognitionModel, self).__init__()\n",
        "        \n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout_rate if num_layers > 1 else 0,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        \n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Linear(hidden_size * 2, 1)  # Bidirectional means *2\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_length, input_size)\n",
        "        \n",
        "        # LSTM output: (batch_size, seq_length, hidden_size * 2)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        \n",
        "        # Attention weights: (batch_size, seq_length, 1)\n",
        "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
        "        \n",
        "        # Apply attention: (batch_size, hidden_size * 2)\n",
        "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        out = self.fc1(context_vector)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "# Define model parameters\n",
        "input_size = X.shape[2]  # Number of features\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Create model\n",
        "model = SignRecognitionModel(\n",
        "    input_size=input_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    num_classes=num_classes\n",
        ").to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n",
        "\n",
        "Let's define the training process for our sign recognition model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create data loaders\n",
        "train_dataset = SignLanguageDataset(X_train, y_train)\n",
        "val_dataset = SignLanguageDataset(X_val, y_val)\n",
        "test_dataset = SignLanguageDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "# Define training function\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Training loop\n",
        "    for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Define validation function\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Validation\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 30\n",
        "early_stopping_patience = 10\n",
        "best_val_loss = float('inf')\n",
        "no_improve_epochs = 0\n",
        "\n",
        "# Lists to store metrics\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "# Uncomment to train the model (will take time)\n",
        "'''\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Print metrics\n",
        "    print(f\"Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), '../src/models/sign_recognition_model.pth')\n",
        "        print(\"Model saved!\")\n",
        "        no_improve_epochs = 0\n",
        "    else:\n",
        "        no_improve_epochs += 1\n",
        "    \n",
        "    # Early stopping\n",
        "    if no_improve_epochs >= early_stopping_patience:\n",
        "        print(f\"No improvement for {early_stopping_patience} epochs. Stopping training.\")\n",
        "        break\n",
        "    \n",
        "    print(\"---\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Let's evaluate our model on the test set and visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define evaluation function\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Store predictions and labels\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    \n",
        "    return np.array(all_predictions), np.array(all_labels)\n",
        "\n",
        "# Visualize training history\n",
        "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accs, label='Training Accuracy')\n",
        "    plt.plot(val_accs, label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Since we haven't actually trained the model, let's create some mock data for visualization\n",
        "mock_train_losses = [0.8, 0.7, 0.6, 0.5, 0.45, 0.42, 0.4, 0.38, 0.36, 0.35]\n",
        "mock_val_losses = [0.85, 0.75, 0.65, 0.58, 0.54, 0.52, 0.5, 0.49, 0.48, 0.48]\n",
        "mock_train_accs = [0.6, 0.7, 0.75, 0.78, 0.8, 0.82, 0.84, 0.85, 0.86, 0.87]\n",
        "mock_val_accs = [0.55, 0.65, 0.7, 0.72, 0.74, 0.75, 0.76, 0.77, 0.77, 0.78]\n",
        "\n",
        "# Plot mock training history\n",
        "plot_training_history(mock_train_losses, mock_val_losses, mock_train_accs, mock_val_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Deployment\n",
        "\n",
        "Finally, let's look at how to deploy the trained model in the SignSpeak application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Save model architecture and weights\n",
        "def save_model(model, save_path, model_info=None):\n",
        "    \"\"\"\n",
        "    Save model and info for deployment.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained PyTorch model\n",
        "        save_path: Path to save the model\n",
        "        model_info: Dictionary with model metadata\n",
        "    \"\"\"\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    \n",
        "    # Save model state\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'model_info': model_info\n",
        "    }, save_path)\n",
        "    \n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Example model info\n",
        "model_info = {\n",
        "    'input_size': input_size,\n",
        "    'hidden_size': hidden_size,\n",
        "    'num_layers': num_layers,\n",
        "    'num_classes': num_classes,\n",
        "    'classes': list(range(num_classes)),  # In a real scenario, these would be actual sign names\n",
        "    'preprocessing': {\n",
        "        'normalize': True,\n",
        "        'frame_length': X.shape[1]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save model (commented out since we haven't actually trained it)\n",
        "# save_model(model, '../src/models/sign_recognition_model.pth', model_info)\n",
        "\n",
        "# Code to load the model for deployment\n",
        "def load_model(model_path, device):\n",
        "    \"\"\"\n",
        "    Load model for deployment.\n",
        "    \n",
        "    Args:\n",
        "        model_path: Path to the saved model\n",
        "        device: Device to load the model on (CPU or GPU)\n",
        "        \n",
        "    Returns:\n",
        "        Loaded model and model info\n",
        "    \"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Model file not found: {model_path}\")\n",
        "        return None, None\n",
        "    \n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model_info = checkpoint.get('model_info', {})\n",
        "    \n",
        "    # Create model with same architecture\n",
        "    model = SignRecognitionModel(\n",
        "        input_size=model_info.get('input_size', 189),\n",
        "        hidden_size=model_info.get('hidden_size', 128),\n",
        "        num_layers=model_info.get('num_layers', 2),\n",
        "        num_classes=model_info.get('num_classes', 5)\n",
        "    ).to(device)\n",
        "    \n",
        "    # Load weights\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    \n",
        "    return model, model_info\n",
        "\n",
        "print(\"To deploy the model in the SignSpeak application, use the load_model function.\")\n",
        "print(\"Example: model, model_info = load_model('src/models/sign_recognition_model.pth', device)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've covered the entire pipeline for training a sign language recognition model:\n",
        "\n",
        "1. Data preparation and loading\n",
        "2. Model architecture design\n",
        "3. Training process\n",
        "4. Model evaluation and visualization\n",
        "5. Model deployment\n",
        "\n",
        "Next steps include gathering real sign language data, fine-tuning the model, and integrating it into the SignSpeak application."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
} 